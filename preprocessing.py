import pandas as pd
import tensorflow as tf
import numpy as np
from tensorflow import keras 
import os
from collections import Counter
import pickle 
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.externals import joblib


cur_path = os.getcwd()

data_path = [os.path.join(os.path.join(cur_path,"non-grouped small dataset"),i) for i in os.listdir(os.path.join(cur_path,"non-grouped small dataset")) if not i.endswith('.ipynb_checkpoints')]

benign = os.listdir(data_path[0])

malware = os.listdir(data_path[1])

for file in benign:
    file_strip = file.split(".exe")[0]
    os.rename(os.path.join(data_path[0],file),os.path.join(data_path[0],file_strip+'.txt'))
    

for file in malware:
    file_strip = file.split('.opseq')[0]
    os.rename(os.path.join(data_path[1],file),os.path.join(data_path[1],file_strip+'.txt'))

benign_files = os.listdir(data_path[0])
malware_files = os.listdir(data_path[1])


count=0
a=[]
for i in range(len(benign_files)):
    f = open(os.path.join(data_path[0],benign_files[i]),'r')
    if (len(f.read())%2) != 0:
        a.append(i)
        count+=1
print(count)

benign_data=[]
for i in range(len(benign_files)):
    f = open(os.path.join(data_path[0],benign_files[i]),'r')
    b = f.read()
    b = b.strip()
    c = len(b)
    d=[]
    j=0
    while c>0:
        if c==1:
            d.append(int(b[-1],16))
            c=c-1
        else:
            d.append(int(b[j:j+2],16))
            j+=2
            c=c-2
    benign_data.append(d)

malware_data=[]
for i in range(len(malware_files)):
    f = open(os.path.join(data_path[1],malware_files[i]),'r')
    b = f.read()
    b = b.strip()
    c = len(b)
    d=[]
    j=0
    while c>0:
        if c==1:
            d.append(int(b[-1],16))
            c=c-1
        else:
            d.append(int(b[j:j+2],16))
            j+=2
            c=c-2
    malware_data.append(d)

with open('benign_data.pkl','wb') as f:
    pickle.dump(benign_data,f)
    

with open('malware_data.pkl','wb') as f:
    pickle.dump(malware_data,f)


a = Counter(benign_data[0])
for i in range(1,len(benign_data)):
    b = Counter(benign_data[i])
    c = sum((a,b), Counter())
    a=c

d = Counter(malware_data[0])
for i in range(1,len(malware_data)):
    b = Counter(malware_data[i])
    e = sum((d,b), Counter())
    d=e

benign_total_count = c
malware_total_count = e

total_count = benign_total_count + malware_total_count

total_op_keys = list(total_count.keys())

with open('total_op_keys.pkl','wb') as f:
    pickle.dump(total_op_keys,f)
    
benign_final=[]
for i in range(len(benign_data)):
    s=[]
    for j in range(len(total_op_keys)):
        s.append(Counter(benign_data[i]).get(total_op_keys[j],0) + 2)
    benign_final.append(s)
    

with open('benign_final.pkl','wb') as f:
    pickle.dump(benign_final,f)

malware_final=[]
for i in range(len(malware_data)):
    s=[]
    for j in range(len(total_op_keys)):
        s.append(Counter(malware_data[i]).get(total_op_keys[j],0) + 2)
    malware_final.append(s)

with open('malware_final.pkl','wb') as f:
    pickle.dump(malware_final,f)

labels_benign = [0]*len(benign_final)
labels_malware = [1]*len(malware_final)
labels = labels_benign + labels_malware

data = benign_final + malware_final

df = pd.DataFrame()
df['data'] = data
df['labels'] = labels

scaler = StandardScaler()


scaler.fit(np.array(list(df['data'])))

data_transform = scaler.transform(np.array(list(df['data'])))

df['transform_data'] = list(data_transform)

df.to_pickle('transformed_data.pkl')

df = df.sample(frac=1)

df.reset_index(drop=True,inplace=True)

dff = df[['transform_data','labels']]

train, test = train_test_split(dff,test_size=0.1)

train.reset_index(drop=True,inplace=True)
test.reset_index(drop=True,inplace=True)
joblib.dump(scaler,'scaler.pkl')

train.to_pickle('train_data.pkl')
test.to_pickle('test_data.pkl')