# -*- coding: utf-8 -*-
"""
Created on Sun Mar 17 17:40:53 2019

@author: lenovo
"""

import numpy as np 
import pandas as pd 
import tensorflow as tf 
from keras.models import load_model
from sklearn.externals import joblib
import pickle
from collections import Counter

model = load_model('best_model.h5')

scaler = joblib.load('scaler.pkl')

predict_data=[]
threshold = 0.8
def predict(filenames):
    for i in range(len(filenames)):
        f = open(filenames[i],'r')
        b = f.read()
        b = b.strip()
        c = len(b)
        d=[]
        j=0
        while c>0:
            if c==1:
                d.append(int(b[-1],16))
                c=c-1
            else:
                d.append(int(b[j:j+2],16))
                j+=2
                c=c-2
        predict_data.append(d)
    
    with open('total_op_keys.pkl','rb') as f:
        total_op_keys = pickle.load(f)
    
    predict_final=[]
    for i in range(len(predict_data)):
        s=[]
        for j in range(len(total_op_keys)):
            s.append(Counter(predict_data[i]).get(total_op_keys[j],0) + 2)
        predict_final.append(s)
    
    predict_transform = scaler.transform(np.array(list(predict_final)))
    
    a = model.predict(predict_transform)
    output=[]
    for i in a:
        if i>threshold:
            output.append(1)
        else:
            output.append(0)
    return output

def main():
    result = predict(['C:\\Users\\lenovo\\Desktop\\project\\non-grouped small dataset\\benign\\00aba9bca89883c2c117b5130be07ae9.txt'])
    print(result)
    return True
main()